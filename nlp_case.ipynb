{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g83QhAFETGkf"
      },
      "source": [
        "# Sentiment Analysis Data\n",
        "## 1. Load Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "EDfy7_koTGk3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqCq04_7axud",
        "outputId": "3eb36aca-cca0-4076-e0d9-35b038af6c34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\nvic\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\nvic\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeMwfelv8xva"
      },
      "source": [
        "## 2. Constant Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kEi_2sy4Hpa3"
      },
      "outputs": [],
      "source": [
        "PREDICTOR = \"text\"\n",
        "LABEL = \"airline_sentiment\"\n",
        "DATASET_PATH = \"data/raw/tweet_airlines.csv\"\n",
        "VECTORIZER_PATH = \"models/vectorizer.pkl\"\n",
        "LABEL_ENCODER_PATH = \"models/le.pkl\"\n",
        "STANDARD_SCALER_PATH = \"models/standard_scaler.pkl\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYyacaMzTGlW"
      },
      "source": [
        "## 3. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vf_loOgs7v4L"
      },
      "outputs": [],
      "source": [
        "def load_data(path: str) -> pd.DataFrame:\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "def get_predictor_and_label(dataset: pd.DataFrame, label: str, predictor: str or list) -> pd.DataFrame:\n",
        "  dataset = dataset.copy()\n",
        "  dataset = pd.concat([dataset[predictor], dataset[label]], axis = 1)\n",
        "  return dataset\n",
        "\n",
        "def duplicates_handler(dataset: pd.DataFrame) -> pd.DataFrame:\n",
        "  dataset = dataset.copy()\n",
        "  dataset.drop_duplicates(inplace = True)\n",
        "  return dataset\n",
        "\n",
        "def data_splitting(dataset: pd.DataFrame, label: str, predictor: str or list) -> pd.DataFrame: \n",
        "    dataset = dataset.copy()\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        dataset[predictor],\n",
        "        dataset[label],\n",
        "        test_size = 0.3,\n",
        "        random_state = 123\n",
        "    )\n",
        "    x_valid, x_test, y_valid, y_test = train_test_split(\n",
        "        x_test,\n",
        "        y_test,\n",
        "        test_size = 0.5,\n",
        "        random_state = 123\n",
        "    )\n",
        "    return x_train, x_valid, x_test, y_train, y_valid, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-SB1OgIATGlg"
      },
      "outputs": [],
      "source": [
        "data = load_data(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IuiRgTq7mbE",
        "outputId": "0b615dea-82c7-4223-e16d-1f752f5649eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14640, 14)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "nth6uFwP8fTu",
        "outputId": "7296d697-b0bd-45d7-e408-c85144655b84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>name</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0            tweet_id airline_sentiment  \\\n",
              "0           0  570306133677760513           neutral   \n",
              "1           1  570301130888122368          positive   \n",
              "2           2  570301083672813571           neutral   \n",
              "3           3  570301031407624196          negative   \n",
              "4           4  570300817074462722          negative   \n",
              "\n",
              "   airline_sentiment_confidence negativereason  negativereason_confidence  \\\n",
              "0                        1.0000            NaN                        NaN   \n",
              "1                        0.3486            NaN                     0.0000   \n",
              "2                        0.6837            NaN                        NaN   \n",
              "3                        1.0000     Bad Flight                     0.7033   \n",
              "4                        1.0000     Can't Tell                     1.0000   \n",
              "\n",
              "          airline        name  retweet_count  \\\n",
              "0  Virgin America     cairdin              0   \n",
              "1  Virgin America    jnardino              0   \n",
              "2  Virgin America  yvonnalynn              0   \n",
              "3  Virgin America    jnardino              0   \n",
              "4  Virgin America    jnardino              0   \n",
              "\n",
              "                                                text tweet_coord  \\\n",
              "0                @VirginAmerica What @dhepburn said.         NaN   \n",
              "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
              "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
              "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
              "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
              "\n",
              "               tweet_created tweet_location               user_timezone  \n",
              "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
              "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
              "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
              "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
              "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6CIrJWotSQ6k"
      },
      "outputs": [],
      "source": [
        "data = get_predictor_and_label(data, LABEL, PREDICTOR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ag3WgjYsSfej",
        "outputId": "7340dde1-292a-4a9f-b57b-910730fd9703"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0                @VirginAmerica What @dhepburn said.           neutral\n",
              "1  @VirginAmerica plus you've added commercials t...          positive\n",
              "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
              "3  @VirginAmerica it's really aggressive to blast...          negative\n",
              "4  @VirginAmerica and it's a really big bad thing...          negative"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pkwNDfeK8Tkd"
      },
      "outputs": [],
      "source": [
        "data = duplicates_handler(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbhlZCtC8XVq",
        "outputId": "35c1df37-759c-4c27-f558-d1ccb0edf78c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14452, 2)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dEtg3DBqTGlk",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "x_train, x_valid, x_test, y_train, y_valid, y_test = data_splitting(data, LABEL, PREDICTOR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU1kseIATGly"
      },
      "source": [
        "## 4. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "9mgmNE0qTGl6"
      },
      "outputs": [],
      "source": [
        "def cleaning_text(data: pd.DataFrame, stemmer, lemmatizer):\n",
        "  data = data.copy()\n",
        "  \n",
        "  clear_text = pd.Series([], dtype = str)\n",
        "\n",
        "  for i, string in enumerate(data):      \n",
        "      # Stemming\n",
        "      string = str(string)\n",
        "      string = string.split(\" \")\n",
        "      string = [stemmer.stem(word) for word in string]\n",
        "      string = \" \".join(string)\n",
        "      string = str(string)\n",
        "      \n",
        "      # Lemmatizing\n",
        "      string = string.split(\" \")\n",
        "      string = [lemmatizer.lemmatize(word) for word in string]\n",
        "      string = \" \".join(string)\n",
        "      string = str(string)\n",
        "\n",
        "      # Preprocess using RegularExpression\n",
        "      string = str(string)\n",
        "      string = re.sub('[^A-Za-z0-9\\']+', ' ', string)\n",
        "      string = re.sub(' +', ' ', string.strip())\n",
        "      string = string.lower()\n",
        "      \n",
        "      # Save to clear_text[i]\n",
        "      clear_text[i] = string\n",
        "\n",
        "  return clear_text\n",
        "\n",
        "def fit_vectorizer(text, path):\n",
        "    tfidf = TfidfVectorizer(min_df = 50, stop_words = \"english\")\n",
        "    tfidf.fit(text)\n",
        "    joblib.dump(tfidf, path)\n",
        "    return tfidf\n",
        "\n",
        "def transform_text(text, vectorizer):\n",
        "    vectorized_text = vectorizer.transform(text)\n",
        "    feature_word = pd.DataFrame(\n",
        "        vectorized_text.toarray(),\n",
        "        columns = vectorizer.get_feature_names_out(), \n",
        "        index = text.index\n",
        "    )\n",
        "    return feature_word\n",
        "  \n",
        "def fit_standard_scaler(data, path):\n",
        "    standard = StandardScaler()\n",
        "    standard.fit(data)\n",
        "    joblib.dump(standard, path)\n",
        "    return standard\n",
        "  \n",
        "def standard_scale_data(data, standard_scaler_object):\n",
        "    data_standard = pd.DataFrame(standard_scaler_object.transform(data))\n",
        "    data_standard.columns = data.columns\n",
        "    data_standard.index = data.index\n",
        "    return data_standard\n",
        "  \n",
        "def le_fit(data, path):\n",
        "    le = LabelEncoder()\n",
        "    le.fit(data)\n",
        "\n",
        "    joblib.dump(le, path)\n",
        "\n",
        "    return le\n",
        "\n",
        "def le_transform(data, le_object):\n",
        "    data = data.copy()\n",
        "    data = le_object.transform(data)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "W9x16Z0DXl0Z"
      },
      "outputs": [],
      "source": [
        "stemmer = SnowballStemmer(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "u_bG2jORTGl8"
      },
      "outputs": [],
      "source": [
        "x_train_cleaned = cleaning_text(x_train, stemmer, lemmatizer)\n",
        "x_valid_cleaned = cleaning_text(x_valid, stemmer, lemmatizer)\n",
        "x_test_cleaned = cleaning_text(x_test, stemmer, lemmatizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "Zm028f0VTGmB"
      },
      "outputs": [],
      "source": [
        "vectorizer = fit_vectorizer(x_train_cleaned, VECTORIZER_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "q9qvvdMFTGmC"
      },
      "outputs": [],
      "source": [
        "x_train_vec = transform_text(x_train_cleaned, vectorizer)\n",
        "x_valid_vec = transform_text(x_valid_cleaned, vectorizer)\n",
        "x_test_vec = transform_text(x_test_cleaned, vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOpN7lg2TGmD",
        "outputId": "96a5b9e2-d4eb-492b-93a1-853a09b7d4dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10116, 327)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_vec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "gQ-LElBLTGmD",
        "outputId": "9f0041ee-4776-42ea-d8c3-43bc18baac8a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>15</th>\n",
              "      <th>1st</th>\n",
              "      <th>20</th>\n",
              "      <th>25</th>\n",
              "      <th>30</th>\n",
              "      <th>40</th>\n",
              "      <th>45</th>\n",
              "      <th>50</th>\n",
              "      <th>...</th>\n",
              "      <th>whi</th>\n",
              "      <th>wife</th>\n",
              "      <th>wifi</th>\n",
              "      <th>won</th>\n",
              "      <th>work</th>\n",
              "      <th>worst</th>\n",
              "      <th>wrong</th>\n",
              "      <th>year</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 327 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    10   11   15  1st   20   25   30   40   45   50  ...  whi  wife  wifi  \\\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   0.0   0.0   \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   0.0   0.0   \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   0.0   0.0   \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   0.0   0.0   \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   0.0   0.0   \n",
              "\n",
              "   won  work  worst  wrong  year  yes  yesterday  \n",
              "0  0.0   0.0    0.0    0.0   0.0  0.0        0.0  \n",
              "1  0.0   0.0    0.0    0.0   0.0  0.0        0.0  \n",
              "2  0.0   0.0    0.0    0.0   0.0  0.0        0.0  \n",
              "3  0.0   0.0    0.0    0.0   0.0  0.0        0.0  \n",
              "4  0.0   0.0    0.0    0.0   0.0  0.0        0.0  \n",
              "\n",
              "[5 rows x 327 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_vec.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ewXT1VSNTGmT"
      },
      "outputs": [],
      "source": [
        "standard_scaler = fit_standard_scaler(x_train_vec, STANDARD_SCALER_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9TwsvPqPjvP3"
      },
      "outputs": [],
      "source": [
        "x_train_scaled = standard_scale_data(x_train_vec, standard_scaler)\n",
        "x_valid_scaled = standard_scale_data(x_valid_vec, standard_scaler)\n",
        "x_test_scaled = standard_scale_data(x_test_vec, standard_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "N-IuUSzhTGmV",
        "outputId": "8c02d609-63a0-471c-a5e8-54c4f96b2696"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>15</th>\n",
              "      <th>1st</th>\n",
              "      <th>20</th>\n",
              "      <th>25</th>\n",
              "      <th>30</th>\n",
              "      <th>40</th>\n",
              "      <th>45</th>\n",
              "      <th>50</th>\n",
              "      <th>...</th>\n",
              "      <th>whi</th>\n",
              "      <th>wife</th>\n",
              "      <th>wifi</th>\n",
              "      <th>won</th>\n",
              "      <th>work</th>\n",
              "      <th>worst</th>\n",
              "      <th>wrong</th>\n",
              "      <th>year</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.107599</td>\n",
              "      <td>-0.072827</td>\n",
              "      <td>-0.080846</td>\n",
              "      <td>-0.075046</td>\n",
              "      <td>-0.085134</td>\n",
              "      <td>-0.06803</td>\n",
              "      <td>-0.107123</td>\n",
              "      <td>-0.071025</td>\n",
              "      <td>-0.076822</td>\n",
              "      <td>-0.06899</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.189738</td>\n",
              "      <td>-0.076294</td>\n",
              "      <td>-0.089355</td>\n",
              "      <td>-0.108521</td>\n",
              "      <td>-0.152032</td>\n",
              "      <td>-0.124006</td>\n",
              "      <td>-0.072238</td>\n",
              "      <td>-0.090145</td>\n",
              "      <td>-0.120185</td>\n",
              "      <td>-0.079535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.107599</td>\n",
              "      <td>-0.072827</td>\n",
              "      <td>-0.080846</td>\n",
              "      <td>-0.075046</td>\n",
              "      <td>-0.085134</td>\n",
              "      <td>-0.06803</td>\n",
              "      <td>-0.107123</td>\n",
              "      <td>-0.071025</td>\n",
              "      <td>-0.076822</td>\n",
              "      <td>-0.06899</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.189738</td>\n",
              "      <td>-0.076294</td>\n",
              "      <td>-0.089355</td>\n",
              "      <td>-0.108521</td>\n",
              "      <td>-0.152032</td>\n",
              "      <td>-0.124006</td>\n",
              "      <td>-0.072238</td>\n",
              "      <td>-0.090145</td>\n",
              "      <td>-0.120185</td>\n",
              "      <td>-0.079535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.107599</td>\n",
              "      <td>-0.072827</td>\n",
              "      <td>-0.080846</td>\n",
              "      <td>-0.075046</td>\n",
              "      <td>-0.085134</td>\n",
              "      <td>-0.06803</td>\n",
              "      <td>-0.107123</td>\n",
              "      <td>-0.071025</td>\n",
              "      <td>-0.076822</td>\n",
              "      <td>-0.06899</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.189738</td>\n",
              "      <td>-0.076294</td>\n",
              "      <td>-0.089355</td>\n",
              "      <td>-0.108521</td>\n",
              "      <td>-0.152032</td>\n",
              "      <td>-0.124006</td>\n",
              "      <td>-0.072238</td>\n",
              "      <td>-0.090145</td>\n",
              "      <td>-0.120185</td>\n",
              "      <td>-0.079535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.107599</td>\n",
              "      <td>-0.072827</td>\n",
              "      <td>-0.080846</td>\n",
              "      <td>-0.075046</td>\n",
              "      <td>-0.085134</td>\n",
              "      <td>-0.06803</td>\n",
              "      <td>-0.107123</td>\n",
              "      <td>-0.071025</td>\n",
              "      <td>-0.076822</td>\n",
              "      <td>-0.06899</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.189738</td>\n",
              "      <td>-0.076294</td>\n",
              "      <td>-0.089355</td>\n",
              "      <td>-0.108521</td>\n",
              "      <td>-0.152032</td>\n",
              "      <td>-0.124006</td>\n",
              "      <td>-0.072238</td>\n",
              "      <td>-0.090145</td>\n",
              "      <td>-0.120185</td>\n",
              "      <td>-0.079535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.107599</td>\n",
              "      <td>-0.072827</td>\n",
              "      <td>-0.080846</td>\n",
              "      <td>-0.075046</td>\n",
              "      <td>-0.085134</td>\n",
              "      <td>-0.06803</td>\n",
              "      <td>-0.107123</td>\n",
              "      <td>-0.071025</td>\n",
              "      <td>-0.076822</td>\n",
              "      <td>-0.06899</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.189738</td>\n",
              "      <td>-0.076294</td>\n",
              "      <td>-0.089355</td>\n",
              "      <td>-0.108521</td>\n",
              "      <td>-0.152032</td>\n",
              "      <td>-0.124006</td>\n",
              "      <td>-0.072238</td>\n",
              "      <td>-0.090145</td>\n",
              "      <td>-0.120185</td>\n",
              "      <td>-0.079535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 327 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         10        11        15       1st        20       25        30  \\\n",
              "0 -0.107599 -0.072827 -0.080846 -0.075046 -0.085134 -0.06803 -0.107123   \n",
              "1 -0.107599 -0.072827 -0.080846 -0.075046 -0.085134 -0.06803 -0.107123   \n",
              "2 -0.107599 -0.072827 -0.080846 -0.075046 -0.085134 -0.06803 -0.107123   \n",
              "3 -0.107599 -0.072827 -0.080846 -0.075046 -0.085134 -0.06803 -0.107123   \n",
              "4 -0.107599 -0.072827 -0.080846 -0.075046 -0.085134 -0.06803 -0.107123   \n",
              "\n",
              "         40        45       50  ...       whi      wife      wifi       won  \\\n",
              "0 -0.071025 -0.076822 -0.06899  ... -0.189738 -0.076294 -0.089355 -0.108521   \n",
              "1 -0.071025 -0.076822 -0.06899  ... -0.189738 -0.076294 -0.089355 -0.108521   \n",
              "2 -0.071025 -0.076822 -0.06899  ... -0.189738 -0.076294 -0.089355 -0.108521   \n",
              "3 -0.071025 -0.076822 -0.06899  ... -0.189738 -0.076294 -0.089355 -0.108521   \n",
              "4 -0.071025 -0.076822 -0.06899  ... -0.189738 -0.076294 -0.089355 -0.108521   \n",
              "\n",
              "       work     worst     wrong      year       yes  yesterday  \n",
              "0 -0.152032 -0.124006 -0.072238 -0.090145 -0.120185  -0.079535  \n",
              "1 -0.152032 -0.124006 -0.072238 -0.090145 -0.120185  -0.079535  \n",
              "2 -0.152032 -0.124006 -0.072238 -0.090145 -0.120185  -0.079535  \n",
              "3 -0.152032 -0.124006 -0.072238 -0.090145 -0.120185  -0.079535  \n",
              "4 -0.152032 -0.124006 -0.072238 -0.090145 -0.120185  -0.079535  \n",
              "\n",
              "[5 rows x 327 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_scaled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FG5qX_TVrz32"
      },
      "outputs": [],
      "source": [
        "le = le_fit(y_train, LABEL_ENCODER_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN7Yzyjsr9iI",
        "outputId": "c49afb60-f2ea-456f-8826-cf37bee63273"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype=object)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OmSMqnDXsGQH"
      },
      "outputs": [],
      "source": [
        "y_train_encoded = le_transform(y_train, le)\n",
        "y_valid_encoded = le_transform(y_valid, le)\n",
        "y_test_encoded = le_transform(y_test, le)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm9MNg3OTGmW"
      },
      "source": [
        "## 5. Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "rsCEqYezTGmX"
      },
      "outputs": [],
      "source": [
        "def dtc_fit(x_train, y_train, scoring = 'accuracy'):\n",
        "    dtc = DecisionTreeClassifier(random_state = 123)\n",
        "\n",
        "    hyperparam = {\n",
        "        'min_samples_leaf': [3, 5, 7, 9, 13, 17, 21, 27, 33, 41, 50, 60, 80, 100],\n",
        "        'max_features': ['sqrt', 'log2', 0.25, 0.5, 0.75]\n",
        "    }\n",
        "\n",
        "    dtc = RandomizedSearchCV(\n",
        "        dtc,\n",
        "        param_distributions = hyperparam,\n",
        "        cv = 5,\n",
        "        n_iter = 15,\n",
        "        scoring = scoring,\n",
        "        n_jobs=-1,\n",
        "        random_state = 123\n",
        "    )\n",
        "    \n",
        "    dtc.fit(x_train, y_train)\n",
        "    \n",
        "    return dtc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ykCR7VvgTGmY"
      },
      "outputs": [],
      "source": [
        "dtc = dtc_fit(x_train_scaled, y_train_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "id": "rU-PWg6DTGmg"
      },
      "outputs": [],
      "source": [
        "def rfc_fit(x_train, y_train, scoring = 'accuracy'):\n",
        "    rfc = RandomForestClassifier(random_state = 123)\n",
        "\n",
        "    hyperparam = {\n",
        "        'min_samples_leaf': [3, 5, 7, 9, 13, 17, 21, 27, 33],\n",
        "        'max_features': [0.25, 0.5, 0.75],\n",
        "        'n_estimators': [30, 40, 60, 100]\n",
        "    }\n",
        "    \n",
        "    rfc = RandomizedSearchCV(\n",
        "        rfc,\n",
        "        param_distributions = hyperparam,\n",
        "        cv = 5,\n",
        "        n_iter = 10,\n",
        "        scoring = scoring,\n",
        "        n_jobs = -1,\n",
        "        random_state = 123,\n",
        "        verbose = 124\n",
        "    )\n",
        "\n",
        "    rfc.fit(x_train, y_train)\n",
        "\n",
        "    return rfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWf75IB2TGmj",
        "outputId": "cc753db1-d116-4a53-8429-5a1d6b35fbff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        }
      ],
      "source": [
        "rfc = rfc_fit(x_train_scaled, y_train_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['models/rfc.pkl']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(dtc, \"models/dtc.pkl\")\n",
        "joblib.dump(rfc, \"models/rfc.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LRxwBhNTGmn"
      },
      "source": [
        "## 6. Evaluation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMukHLv2nJjy",
        "outputId": "32791081-2720-4e0c-9c74-515aadec520a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.90      0.82      1393\n",
            "           1       0.48      0.25      0.33       453\n",
            "           2       0.59      0.50      0.54       322\n",
            "\n",
            "    accuracy                           0.70      2168\n",
            "   macro avg       0.61      0.55      0.56      2168\n",
            "weighted avg       0.67      0.70      0.68      2168\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = dtc.predict(x_valid_scaled)\n",
        "print(classification_report(y_valid_encoded, y_pred, zero_division = 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhFt5A7hnbPd",
        "outputId": "f49957c3-f896-4055-f26c-d276e8c0e0de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.92      0.84      1393\n",
            "           1       0.57      0.32      0.41       453\n",
            "           2       0.69      0.50      0.58       322\n",
            "\n",
            "    accuracy                           0.73      2168\n",
            "   macro avg       0.67      0.58      0.61      2168\n",
            "weighted avg       0.71      0.73      0.71      2168\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = rfc.predict(x_valid_scaled)\n",
        "print(classification_report(y_valid_encoded, y_pred, zero_division = 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHHudkC7oDf5"
      },
      "source": [
        "## 7. Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BLZjKDL_ox2K"
      },
      "outputs": [],
      "source": [
        "def manual_predict(text_data, model, stemmer, lemmatizer, vectorizer, standard_scaler, le):\n",
        "  manual_data = text_data.copy()\n",
        "  manual_data_cleaned = cleaning_text(manual_data, stemmer, lemmatizer)\n",
        "  manual_data_vec = transform_text(manual_data_cleaned, vectorizer)\n",
        "  manual_data_scaled = standard_scale_data(manual_data_vec, standard_scaler)\n",
        "  y_pred = model.predict(manual_data_scaled)\n",
        "\n",
        "  y_pred = le.inverse_transform(y_pred)\n",
        "\n",
        "  return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "collapsed": true,
        "id": "65H9awG8TGmy"
      },
      "outputs": [],
      "source": [
        "y_pred = manual_predict(x_test, dtc, stemmer, lemmatizer, vectorizer, standard_scaler, le)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Yv3x2EFdum7N"
      },
      "outputs": [],
      "source": [
        "data_test = pd.concat([x_test, y_test, pd.Series(y_pred).set_axis(y_test.index)], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YExkdAmtwHgw",
        "outputId": "7f947e9e-ccf4-4e31-c351-6fa90b368831"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14165</th>\n",
              "      <td>@AmericanAir agents refuse to help, \"too busy\"...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8932</th>\n",
              "      <td>@JetBlue unfortunately no, but hoping I can ca...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1411</th>\n",
              "      <td>@united you're my early frontrunner for best a...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10482</th>\n",
              "      <td>@USAirways can you DM me please?</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8693</th>\n",
              "      <td>@JetBlue can I change my flight if I already p...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6330</th>\n",
              "      <td>@SouthwestAir Secondly, we did not begin board...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10128</th>\n",
              "      <td>@USAirways have had a medical issue Late Fligh...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3225</th>\n",
              "      <td>@united WHAT?! Y'all have zero concept of cust...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4758</th>\n",
              "      <td>@southwestair does anyone realize that banning...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2117</th>\n",
              "      <td>@united not a good day to fly u, two delayed f...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2168 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text airline_sentiment  \\\n",
              "14165  @AmericanAir agents refuse to help, \"too busy\"...          negative   \n",
              "8932   @JetBlue unfortunately no, but hoping I can ca...           neutral   \n",
              "1411   @united you're my early frontrunner for best a...          positive   \n",
              "10482                   @USAirways can you DM me please?           neutral   \n",
              "8693   @JetBlue can I change my flight if I already p...           neutral   \n",
              "...                                                  ...               ...   \n",
              "6330   @SouthwestAir Secondly, we did not begin board...          negative   \n",
              "10128  @USAirways have had a medical issue Late Fligh...          negative   \n",
              "3225   @united WHAT?! Y'all have zero concept of cust...          negative   \n",
              "4758   @southwestair does anyone realize that banning...          negative   \n",
              "2117   @united not a good day to fly u, two delayed f...          negative   \n",
              "\n",
              "              0  \n",
              "14165  negative  \n",
              "8932   positive  \n",
              "1411   negative  \n",
              "10482  negative  \n",
              "8693   negative  \n",
              "...         ...  \n",
              "6330   negative  \n",
              "10128  negative  \n",
              "3225   negative  \n",
              "4758   negative  \n",
              "2117   negative  \n",
              "\n",
              "[2168 rows x 3 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QrYhRBIkwshR",
        "outputId": "734a0285-5e8b-4fde-9ac2-95af3703d1c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1411</th>\n",
              "      <td>@united you're my early frontrunner for best a...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4184</th>\n",
              "      <td>@united thank you! 😊</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12372</th>\n",
              "      <td>@AmericanAir mission accomplished today, Thank...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2914</th>\n",
              "      <td>@united of course not. The inflight crew was g...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8351</th>\n",
              "      <td>@JetBlue, never been delayed before; 533 to TP...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2035</th>\n",
              "      <td>@united thanks for the epic service on 863- al...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4455</th>\n",
              "      <td>@SouthwestAir @intuit @jhamilton2007 4 moms, 4...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>@united this will definitely be a trip to reme...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7561</th>\n",
              "      <td>@JetBlue I love #JetBlue ! #FlyFi when will we...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3715</th>\n",
              "      <td>@united Will have to try standby in Denver ton...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>349 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text airline_sentiment  \\\n",
              "1411   @united you're my early frontrunner for best a...          positive   \n",
              "4184                                @united thank you! 😊          positive   \n",
              "12372  @AmericanAir mission accomplished today, Thank...          positive   \n",
              "2914   @united of course not. The inflight crew was g...          positive   \n",
              "8351   @JetBlue, never been delayed before; 533 to TP...          positive   \n",
              "...                                                  ...               ...   \n",
              "2035   @united thanks for the epic service on 863- al...          positive   \n",
              "4455   @SouthwestAir @intuit @jhamilton2007 4 moms, 4...          positive   \n",
              "723    @united this will definitely be a trip to reme...          positive   \n",
              "7561   @JetBlue I love #JetBlue ! #FlyFi when will we...          positive   \n",
              "3715   @united Will have to try standby in Denver ton...          positive   \n",
              "\n",
              "              0  \n",
              "1411   negative  \n",
              "4184   positive  \n",
              "12372  positive  \n",
              "2914   positive  \n",
              "8351    neutral  \n",
              "...         ...  \n",
              "2035   positive  \n",
              "4455    neutral  \n",
              "723    negative  \n",
              "7561   positive  \n",
              "3715   negative  \n",
              "\n",
              "[349 rows x 3 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_test[data_test[\"airline_sentiment\"] == \"positive\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xDGS2AwvxCZo",
        "outputId": "ba751730-764e-4180-ea4f-547551dd4829"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'@united of course not. The inflight crew was great!'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_test.loc[2914].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJLQO30cxNif"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vimoBh0DTGms"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2bf52b971b2acbd98497d46dd742eaa8bec702053ab6f6e8698c957dc949d395"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
